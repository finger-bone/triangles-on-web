<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://finger-bone.github.io/triangles-on-web/04/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Orthographic Projection - Introduction to WebGPU</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/color-brewer.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Introduction to WebGPU</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">2D Basics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../01/" class="dropdown-item">Basic Setup</a>
</li>
                                    
<li>
    <a href="../02/" class="dropdown-item">Life Game</a>
</li>
                                    
<li>
    <a href="../03/" class="dropdown-item">Texture</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">3D Basics <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="./" class="dropdown-item active">Orthographic Projection</a>
</li>
                                    
<li>
    <a href="../05/" class="dropdown-item">Perspective Projection</a>
</li>
                                    
<li>
    <a href="../06/" class="dropdown-item">Lighting</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="../07/" class="nav-link">WGSL</a>
                            </li>
                            <li class="navitem">
                                <a href="../08/" class="nav-link">3D Models</a>
                            </li>
                            <li class="navitem">
                                <a href="../09/" class="nav-link">Curves and Surfaces</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../03/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../05/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#triangles-on-web-ch4-orthographic-projection" class="nav-link">Triangles on Web Ch4 Orthographic Projection</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#orthographic-projection" class="nav-link">Orthographic Projection</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#manual-depth-test" class="nav-link">Manual Depth Test</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#rotate-the-cube" class="nav-link">Rotate the Cube</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="triangles-on-web-ch4-orthographic-projection">Triangles on Web Ch4 Orthographic Projection</h1>
<p>From this part, we will go into the world of 3D graphics. We will learn about the basic concepts of 3D rendering.</p>
<p>But before building the simulation, we have a lot to learn- perspective and lighting, to be specific.</p>
<p>In this part, we will learn about perspective. We will learn how to project 3D objects onto a 2D screen, and how to create a perspective camera.</p>
<p>Of course, a simpler way would be to use orthographic projection, which we will also learn about.</p>
<p>Perspective is a projection method that provide verisimilitude to the 3D world. It is the most common projection method in computer graphics. But previously, we learnt that NDC has three axis. So why do we need to project 3D objects onto a 2D screen?</p>
<p>The z axis of NDC is depth, not the distance from the camera. So, instead of the z-axis, it is more like a layer of the 3D world. The smaller z-axis will get prioritized in things like depth test.</p>
<h2 id="orthographic-projection">Orthographic Projection</h2>
<p>Orthographic projection is a projection method that does not take perspective into account. That is, it does not make objects smaller as they go further away from the camera. This is useful for technical drawings, but not for realistic rendering.</p>
<p>Orthographic projection is a projection, that is, in a mathematical sense,</p>
<p>
<script type="math/tex; mode=display">
view_{point} = orthographic( model_{point})
</script>
</p>
<p>Where <code>veiw_{point}</code> is the NDC point, and <code>model_{point}</code> is the 3D point. The <code>orthographic</code> function is the orthographic projection function.</p>
<p>Now let's see how we should implement the <code>orthographic</code> function.</p>
<h3 id="how-orthographic-projection-works">How Orthographic Projection Works</h3>
<p>In orthographic projection, it is said that straight lines should remain straight, and parallel lines should remain parallel. Or alteratively, the transformation should be linear.</p>
<p><img alt="Orthographic Projection" src="image.png" /></p>
<p>The left is the actual 3D model, also called the world space. The right is the 2D screen, also called the screen space.</p>
<p>Depending on the axis of the projected view, the orthographic projection can be divided into many types,</p>
<p><img alt="Different Orthographic Projections" src="image-1.png" /></p>
<p>The first panel is perspective projection, which we will learn about later, it is for comparison.</p>
<p>The above image shows different kind of orthographic projections. But actually, there is only one kind of orthographic projection, if we treat their difference as parameters. That is, we can use a matrix to represent orthographic projection.</p>
<p>Now let's do the math.</p>
<h3 id="using-matrix-for-orthographic-projection">Using Matrix for Orthographic Projection</h3>
<p>Before we do the math, we have two sets of axis to consider,</p>
<ul>
<li>The world axis, which is the actual 3D model.</li>
<li>The screen axis, which is the actual 2D screen. x-axis is always horizontal, y-axis is always vertical.</li>
</ul>
<p>They will later be noted with subscripts <script type="math/tex">w</script> and <script type="math/tex">s</script> respectively.</p>
<p>In orthographic projection, because during the transformation, the parallel lines should remain parallel, we can conclude that it is a linear transformation. That is, we can use a matrix to represent it.</p>
<p>To actually get the matrix, we need to know how the bases of the world axis are projected onto the screen axis. The different choices of the bases will result in different orthographic projections. But typically, y-axis will remain the same, and z-axis will be projected.</p>
<p>So, we can have the following matrix,</p>
<p>
<script type="math/tex; mode=display">
r_s = M \cdot r_w
</script>
</p>
<p>Where <script type="math/tex">r_s</script> is the screen space vector, <script type="math/tex">r_w</script> is the world space vector, and <script type="math/tex">M</script> is the orthographic projection matrix, varied based on the orthographic projection type.</p>
<p>Some typical orthographic projections are shown below,</p>
<h4 id="top-view">Top View</h4>
<p>In top view, the x-axis is projected onto the x-axis, and the z-axis is projected onto the y-axis.</p>
<p>
<script type="math/tex; mode=display">  
\begin{bmatrix}
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{bmatrix}
</script>
</p>
<p>This just puts z-axis onto the x-axis, then completely ignores the world x-axis.</p>
<h4 id="front-view">Front View</h4>
<p>In front view, the x-axis is projected onto the x-axis, and the y-axis is projected onto the y-axis.</p>
<p>
<script type="math/tex; mode=display">
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{bmatrix}
</script>
</p>
<p>This just puts the world axis onto the screen axis, while ignoring the z-axis.</p>
<h4 id="isometric-view">Isometric View</h4>
<p>In isometric view, the projected x-axis, y-axis and z-axis will have a 120 degree angle between each other.</p>
<p>
<script type="math/tex; mode=display">
\begin{bmatrix}
\cos(\frac{\pi}{6}) & 0 & -\cos(\frac{\pi}{6}) \\
-\sin(\frac{\pi}{6}) & 1 & -\sin(\frac{\pi}{6}) \\
\end{bmatrix}
</script>
</p>
<p>This is a bit more complicated, but it allows us to actually see the 3D object, instead of just one view.</p>
<h4 id="oblique-view">Oblique View</h4>
<p>In oblique view, the x-axis and y-axis stays, z-axis will be 45 degree to the x-axis, with a compression factor of <script type="math/tex">\frac{1}{2}</script>.</p>
<p>
<script type="math/tex; mode=display">
\begin{bmatrix}
1 & 0 & \frac{1}{2\sqrt{2}} \\
0 & 1 & \frac{1}{2\sqrt{2}} \\
\end{bmatrix}
</script>
</p>
<p>This is the most traditional orthographic projection, and is used in technical drawings.</p>
<h3 id="show-a-cube-with-orthographic-projection">Show a Cube with Orthographic Projection</h3>
<p>Now, let's recapitulate on how to setup WebGPU.</p>
<p>First, get an adapter, then request a device.</p>
<pre><code class="language-typescript">const requestDevice = async (): Promise&lt;[GPUAdapter, GPUDevice] | null&gt; =&gt; {
    const adapter = await navigator.gpu.requestAdapter();
    if (!adapter) {
        console.error('WebGPU not supported');
        return null;
    }
    const device = await adapter.requestDevice();
    console.log(device);
    return [adapter, device];
}
</code></pre>
<p>Then, we need to get the canvas and its context.</p>
<pre><code class="language-typescript">const getContext = async (device: GPUDevice): Promise&lt;[GPUCanvasContext, GPUTextureFormat]&gt; =&gt; {
    const canvas = document.getElementById('app') as HTMLCanvasElement;
    const context = canvas.getContext(&quot;webgpu&quot;)!;
    const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
    context.configure({
        device: device,
        format: canvasFormat,
    });
    return [context, canvasFormat];
}
</code></pre>
<p>Then, we need a shader module. Like we previously discussed, the transformation of Orthographic Projection is a point-wise operation, so we only need a vertex shader. We need to perform matrix multiplication in the shader.</p>
<pre><code class="language-typescript">const get_shader = async (device: GPUDevice): Promise&lt;GPUShaderModule&gt; =&gt; {
    return device.createShaderModule({
        label: &quot;sm&quot;,
        code: `
        @vertex
        fn vertexMain(@location(0) position: vec3&lt;f32&gt;) -&gt; vec4&lt;f32&gt; {
            var projection: mat3x2&lt;f32&gt; = mat3x2&lt;f32&gt;(
                vec2&lt;f32&gt;(1.0, 0.0),
                vec2&lt;f32&gt;(0.0, 1.0),
                vec2&lt;f32&gt;(0.3535533906, 0.3535533906)
            );
            return vec4&lt;f32&gt;(projection * position, 0.0, 1.0);
        }

        @fragment
        fn fragmentMain() -&gt; vec4&lt;f32&gt; {
            return vec4&lt;f32&gt;(0.0, 0.0, 1.0, 1.0);
        }
        `,
    })
}
</code></pre>
<p>Here we used the oblique view matrix, which is the most traditional orthographic projection matrix. We also used a blue color for the cube.</p>
<p>Then, the vertex buffer,</p>
<pre><code class="language-typescript">
const get_vertices = (device: GPUDevice): [GPUBuffer, GPUVertexBufferLayout] =&gt; {
    // cube
    // use triangle
    const vertices = new Float32Array([
        // xy
        1.0, 0.0, 0.0,
        0.0, 1.0, 0.0,
        0.0, 0.0, 0.0,

        1.0, 0.0, 0.0,
        0.0, 1.0, 0.0,
        1.0, 1.0, 0.0,

        1.0, 0.0, 1.0,
        0.0, 1.0, 1.0,
        0.0, 0.0, 1.0,

        1.0, 0.0, 1.0,
        0.0, 1.0, 1.0,
        1.0, 1.0, 1.0,
        // yz
        0.0, 1.0, 0.0,
        0.0, 0.0, 1.0,
        0.0, 0.0, 0.0,

        0.0, 1.0, 0.0,
        0.0, 0.0, 1.0,
        0.0, 1.0, 1.0,

        1.0, 1.0, 0.0,
        1.0, 0.0, 1.0,
        1.0, 0.0, 0.0,

        1.0, 1.0, 0.0,
        1.0, 0.0, 1.0,
        1.0, 1.0, 1.0,
        // zx
        0.0, 0.0, 1.0,
        1.0, 0.0, 0.0,
        1.0, 0.0, 1.0,

        0.0, 0.0, 1.0,
        1.0, 0.0, 0.0,
        0.0, 0.0, 0.0,

        0.0, 1.0, 1.0,
        1.0, 1.0, 0.0,
        1.0, 1.0, 1.0,

        0.0, 1.0, 1.0,
        1.0, 1.0, 0.0,
        0.0, 1.0, 0.0,
    ]).map((v) =&gt; v * 0.5 - 0.25);
    const layout: GPUVertexBufferLayout = {
        arrayStride: 3 * 4,
        attributes: [{
            format: &quot;float32x3&quot;,
            offset: 0,
            shaderLocation: 0,
        }]
    }
    const buffer = device.createBuffer({
        size: vertices.length * 4,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
    })
    device.queue.writeBuffer(buffer, 0, vertices.buffer);
    return [buffer, layout];
}
</code></pre>
<p>Then the render pipeline,</p>
<pre><code class="language-typescript">const encoder = device.createCommandEncoder();

const renderPassDescriptor: GPURenderPassDescriptor = {
    colorAttachments: [{
        view: ctx.getCurrentTexture().createView(),
        clearValue: { r: 0.1, g: 0.3, b: 0.2, a: 1.0 },
        storeOp: &quot;store&quot;,
        loadOp: &quot;clear&quot;,
    }]
}

const pass = encoder.beginRenderPass(renderPassDescriptor);
const pipelineLayout = device.createPipelineLayout({
    bindGroupLayouts: [],
});
const pipeline = device.createRenderPipeline({
    layout: pipelineLayout,
    vertex: {
        module: shader,
        entryPoint: &quot;vertexMain&quot;,
        buffers: [vertexBufferLayout],
    },
    fragment: {
        module: shader,
        entryPoint: &quot;fragmentMain&quot;,
        targets: [{
            format: format,
        }]
    },
});
</code></pre>
<p>Finally, let's set off the render,</p>
<pre><code class="language-typescript">pass.setPipeline(pipeline);
pass.setVertexBuffer(0, vertices);
pass.draw(6 * 2 * 3);
pass.end();
const command = encoder.finish();
device.queue.submit([command]);
</code></pre>
<p>Now, you should see a cube-shaped object on the screen.</p>
<p>Of course, you can also try other orthographic projections.</p>
<p>However, there is a problem- the perspective matrix is used in every vertex and the same- but they need to be created for each render. The way to solve this is to use a uniform buffer.</p>
<h3 id="using-uniform-buffer">Using Uniform Buffer</h3>
<p>A uniform buffer is a buffer that is shared between the CPU and the GPU. It is used to store data that is shared between all vertices or fragments.</p>
<p>Different from storage buffer, uniform buffer is read-only, and is used to store data that is constant during the rendering process.</p>
<p>To use a uniform buffer, we need to create a buffer, and then bind it to the pipeline.</p>
<pre><code class="language-typescript">const projectionMatrix = new Float32Array([
    1.0, 0.0,
    0.0, 1.0,
    0.3535533906, 0.3535533906,
]);
const projectionBuffer = device.createBuffer({
    size: 6 * 4,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
});
device.queue.writeBuffer(
    projectionBuffer,
    0,
    projectionMatrix.buffer,
)
</code></pre>
<pre><code class="language-typescript">const bindGroupLayout = device.createBindGroupLayout({
    entries: [
        {
            binding: 0,
            visibility: GPUShaderStage.VERTEX,
            buffer: {   
                type: &quot;uniform&quot;
            }
        }
    ]
});
const bindGroup = device.createBindGroup({
    layout: bindGroupLayout,
    entries: [
        {
            binding: 0,
            resource: {
                buffer: projectionBuffer,
            }
        }
    ]
});

const pipelineLayout = device.createPipelineLayout({
    bindGroupLayouts: [bindGroupLayout]
});
</code></pre>
<pre><code class="language-typescript">pass.setBindGroup(0, bindGroup);
</code></pre>
<pre><code class="language-wgsl">@group(0) @binding(0) var&lt;uniform&gt; projection: mat3x2&lt;f32&gt;;

struct VertexOutput {
    @builtin(position) pos: vec4f,
    @location(0) @interpolate(flat) face: u32,
};

@vertex
fn vertexMain(@location(0) position: vec3f, @builtin(vertex_index) vertexIndex: u32) -&gt; VertexOutput {
    let projected = projection * position;
    let final_position = vec4&lt;f32&gt;(projected, 0.0, 1.0);
    var output = VertexOutput(final_position, vertexIndex / 6);
    return output;
}
</code></pre>
<p>Now the projection matrix is shared between all vertices.</p>
<h3 id="color">Color</h3>
<p>We would like different colors for different faces. We can do this by passing the color as an attribute to the vertex shader.</p>
<pre><code class="language-typescript">const get_shader = async (device: GPUDevice): Promise&lt;GPUShaderModule&gt; =&gt; {
    return device.createShaderModule({
        label: &quot;sm&quot;,
        code: `
        struct VertexOutput {
            @builtin(position) pos: vec4f,
            @location(0) @interpolate(flat) face: u32,
        };

        @vertex
        fn vertexMain(@location(0) position: vec3f, @builtin(vertex_index) vertexIndex: u32) -&gt; VertexOutput {
            let projection: mat3x2&lt;f32&gt; = mat3x2&lt;f32&gt;(
                vec2&lt;f32&gt;(1.0, 0.0),
                vec2&lt;f32&gt;(0.0, 1.0),
                vec2&lt;f32&gt;(0.3535533906, 0.3535533906)
            );
            let projected = projection * position;
            let final_position = vec4&lt;f32&gt;(projected, 0.0, 1.0);
            var output = VertexOutput(final_position, vertexIndex / 6);
            return output;
        }

        @fragment
        fn fragmentMain(input: VertexOutput) -&gt; vec4&lt;f32&gt; {
            if (input.face == 0u) {
                return vec4&lt;f32&gt;(1.0, 0.0, 0.0, 1.0);
            } else if (input.face == 1u) {
                return vec4&lt;f32&gt;(0.0, 1.0, 0.0, 1.0);
            } else if (input.face == 2u) {
                return vec4&lt;f32&gt;(0.0, 0.0, 1.0, 1.0);
            } else if (input.face == 3u) {
                return vec4&lt;f32&gt;(1.0, 1.0, 0.0, 1.0);
            } else if (input.face == 4u) {
                return vec4&lt;f32&gt;(1.0, 0.0, 1.0, 1.0);
            } else {
                return vec4&lt;f32&gt;(0.0, 1.0, 1.0, 1.0);
            }
        }
        `,
    })
}
</code></pre>
<p>But as you do this, you'd find something horrible- we do not have depth system, and thus, the back faces overlap the front faces.</p>
<p>Of course, an easy way to solve this just adding the original depth value to the fragment shader, then discard the fragment if the depth value is larger. However, this is so common and most GPU have a built-in depth test system.</p>
<h2 id="manual-depth-test">Manual Depth Test</h2>
<p>Here we will manually write the depth value to the depth texture. Later, we will learn about using default depth test system.</p>
<p>Depth test is a test that is performed to determine whether a fragment should be drawn. It is based on the depth value of the fragment.</p>
<p>In depth test, there is a buffer called the depth texture, which stores the depth value of each pixel.</p>
<p>Vertex shader will create multiple primitives, which will be rasterized into fragments. When this happens, the depth value of the fragment will be compared with the depth value in the depth texture. If the depth value of the fragment is smaller, the fragment will be drawn.</p>
<p>For example, if we have two overlapping triangles, when the front triangle is drawn, the depth value of the fragment will be written to the depth texture. When the back triangle is drawn, the depth value of the fragment will be compared with the depth value in the depth texture. If the depth value of the fragment is larger, the fragment will be discarded. Again, fragment is just a fancy name for pixel.</p>
<p>From the above, you can tell that there needs to be a space where we store the depth value of each pixel. This is the depth texture.</p>
<p>Let's create a depth texture.</p>
<pre><code class="language-typescript">const get_depth_texture = (device: GPUDevice, size: { width: number, height: number }): GPUTexture =&gt; {
    return device.createTexture({
        size: {
            width: size.width,
            height: size.height,
            depthOrArrayLayers: 1
        },
        format: &quot;depth24plus&quot;,
        usage: GPUTextureUsage.RENDER_ATTACHMENT,
    });
}
</code></pre>
<p>Please note one parameter, <code>depthOrArrayLayers</code>. When we are talking about 3D textures, this parameter will be the depth of the texture. But when we are talking about depth textures, this parameter will be the number of layers.</p>
<p>However, when performing depth test, obviously, we only need a 2D layer for storing the depth value.</p>
<p>Now we add a new attachment, the <code>depthAndStencilAttachment</code>.</p>
<pre><code class="language-typescript">const renderPassDescriptor: GPURenderPassDescriptor = {
    colorAttachments: [{
        view: ctx.getCurrentTexture().createView(),
        clearValue: { r: 0.1, g: 0.3, b: 0.2, a: 1.0 },
        storeOp: &quot;store&quot;,
        loadOp: &quot;clear&quot;,
    }],
    depthStencilAttachment: {
        view: depthTexture.createView(),
        depthClearValue: 1.0,
        depthStoreOp: &quot;store&quot;,
        depthLoadOp: &quot;clear&quot;,
    }
}

// ...

const pipeline = device.createRenderPipeline({
    layout: pipelineLayout,
    vertex: {
        module: shader,
        entryPoint: &quot;vertexMain&quot;,
        buffers: [vertexBufferLayout],
    },
    fragment: {
        module: shader,
        entryPoint: &quot;fragmentMain&quot;,
        targets: [{
            format: format,
        }]
    },
    depthStencil: {
        format: &quot;depth24plus&quot;,
        depthWriteEnabled: true,
        depthCompare: &quot;less&quot;,
    }
});
</code></pre>
<p>Remember what an attachment is? It is something that is attached to the render pass, or the target of the render pass. In this case, the depth texture is attached to the render pass.</p>
<p><code>depthCompare</code> is the comparison function. It is used to compare the depth value of the fragment with the depth value in the depth texture. If set to <code>less</code>, the smaller depth value will be drawn.</p>
<p><code>depthWriteEnabled</code> is used to determine whether the depth value of the fragment will be written to the depth texture. If set to <code>false</code>, the depth value of the fragment will not be written to the depth texture.</p>
<p>Now you see a cube with different colors on different faces- but some color block are still wrongly overlapped. This is because we did the perspective ourselves- and left z-axis as 0. This is not the actual depth value, and the depth test system will not work.</p>
<p>To solve this, we need to write the depth value to the depth texture, or you can correctly set z-axis. Since we haven't yet talked about clip space, we will write the depth value to the depth texture.</p>
<p>First, we need to ask the vertex shader to output the depth value.</p>
<p>Please note that the depth should be within 0 to 1, so normalize the depth value (although we did not use the part of the z that's smaller than one, you can't ignore that depth or else the rendering will be wrong, we still have to divide by 2 then add 0.5).</p>
<pre><code class="language-wgsl">struct VertexOutput {
    @builtin(position) pos: vec4f,
    @location(0) @interpolate(flat) face: u32,
    @location(1) depth: f32,
};

@vertex
fn vertexMain(@location(0) position: vec3f, @builtin(vertex_index) vertexIndex: u32) -&gt; VertexOutput {
    let projected = projection * position;
    let final_position = vec4&lt;f32&gt;(projected, 0.0, 1.0);
    let depth = position.z * 0.5 + 0.5;
    var output = VertexOutput(final_position, vertexIndex / 6, depth);
    return output;
}
</code></pre>
<p>Instead of returning only the color attachment, which is defined by location (since there allows multiple color attachments), we also return the depth value, it is <code>@builtin(frag_depth)</code>.</p>
<pre><code class="language-wgsl">struct FragmentOutput {
    @location(0) color: vec4&lt;f32&gt;,
    @builtin(frag_depth) depth: f32,
};

@fragment
fn fragmentMain(input: VertexOutput) -&gt; FragmentOutput {
    var output = FragmentOutput(vec4&lt;f32&gt;(1.0, 1.0, 1.0, 1.0), input.depth);
    if (input.face == 0u) {
        output.color = vec4&lt;f32&gt;(1.0, 0.0, 0.0, 1.0);
    } else if (input.face == 1u) {
        output.color = vec4&lt;f32&gt;(0.0, 1.0, 0.0, 1.0);
    } else if (input.face == 2u) {
        output.color = vec4&lt;f32&gt;(0.0, 0.0, 1.0, 1.0);
    } else if (input.face == 3u) {
        output.color = vec4&lt;f32&gt;(1.0, 1.0, 0.0, 1.0);
    } else if (input.face == 4u) {
        output.color = vec4&lt;f32&gt;(1.0, 0.0, 1.0, 1.0);
    } else {
        output.color = vec4&lt;f32&gt;(0.0, 1.0, 1.0, 1.0);
    }
    return output;
}
</code></pre>
<p>Now you should see a perfect cube. However, it definitely seems a bit off- since orthographic projection is not perspective projection, and although it has the same length in the front and in the back for a pair of parallel lines, your eyes believes that the lines that are further away should be shorter. Now, they are of the same length, so you perceive the cube as the farther side being larger.</p>
<p>You can adjust the orthographic projection matrix to make the cube look more realistic.</p>
<p>There might be a small margin of face that should have been drawn but is not. This is because of some floating point error when the value is compared. You can adjust the comparison function to <code>less-equal</code> to mitigate this. But if you want to eliminate this, you need some fine-tuning on the depth value- we are not doing that here since it doesn't affect the overall look too much.</p>
<p>You can also set different comparison functions for the depth test, to see how other comparison functions work.</p>
<h2 id="rotate-the-cube">Rotate the Cube</h2>
<p>Now, let's get the cube moving. We have a simple way- we will have a slider on the web page, then pass the angle to the vertex shader to ask it to rotate the cube.</p>
<pre><code class="language-html">&lt;input type=&quot;range&quot; id=&quot;angle&quot; min=&quot;-180&quot; max=&quot;180&quot; step=&quot;0.1&quot; value=&quot;0&quot; /&gt;
</code></pre>
<p>We need a render loop.</p>
<pre><code class="language-typescript">const render = () =&gt; {
    const depthTexture = get_depth_texture(device, { width: ctx.canvas.width, height: ctx.canvas.height });

    const encoder = device.createCommandEncoder();

    const renderPassDescriptor: GPURenderPassDescriptor = {
        colorAttachments: [{
            view: ctx.getCurrentTexture().createView(),
            clearValue: { r: 0.1, g: 0.3, b: 0.2, a: 1.0 },
            storeOp: &quot;store&quot;,
            loadOp: &quot;clear&quot;,
        }],
        depthStencilAttachment: {
            view: depthTexture.createView(),
            depthClearValue: 1.0,
            depthStoreOp: &quot;store&quot;,
            depthLoadOp: &quot;clear&quot;,
        }
    }
    const pass = encoder.beginRenderPass(renderPassDescriptor);

    const bindGroupLayout = device.createBindGroupLayout({
        entries: [
            {
                binding: 0,
                visibility: GPUShaderStage.VERTEX,
                buffer: {   
                    type: &quot;uniform&quot;
                }
            }
        ]
    });
    const bindGroup = device.createBindGroup({
        layout: bindGroupLayout,
        entries: [
            {
                binding: 0,
                resource: {
                    buffer: projectionBuffer,
                }
            }
        ]
    });

    const pipelineLayout = device.createPipelineLayout({
        bindGroupLayouts: [bindGroupLayout]
    });
    const pipeline = device.createRenderPipeline({
        layout: pipelineLayout,
        vertex: {
            module: shader,
            entryPoint: &quot;vertexMain&quot;,
            buffers: [vertexBufferLayout],
        },
        fragment: {
            module: shader,
            entryPoint: &quot;fragmentMain&quot;,
            targets: [{
                format: format,
            }]
        },
        depthStencil: {
            format: &quot;depth24plus&quot;,
            depthWriteEnabled: true,
            depthCompare: &quot;less-equal&quot;,
        }
    });
    pass.setPipeline(pipeline);
    pass.setBindGroup(0, bindGroup);
    pass.setVertexBuffer(0, vertices);
    pass.draw(6 * 2 * 3);
    pass.end();
    const command = encoder.finish();
    device.queue.submit([command]);
}
setInterval(render, 1000 / 60);
</code></pre>
<p>We will use uniform buffer to pass the angle to the vertex shader.</p>
<pre><code class="language-typescript">const angle = document.getElementById(&quot;angle&quot;) as HTMLInputElement;
const angleBuffer = new Float32Array([parseFloat(angle.value) * (
    Math.PI / 180
)]);
const angleBufferGPU = device.createBuffer({
    size: 4,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
});
device.queue.writeBuffer(
    angleBufferGPU,
    0,
    angleBuffer.buffer,
);
const bindGroupLayout = device.createBindGroupLayout({
    entries: [
        {
            binding: 0,
            visibility: GPUShaderStage.VERTEX,
            buffer: {   
                type: &quot;uniform&quot;
            }
        },
        {
            binding: 1,
            visibility: GPUShaderStage.VERTEX,
            buffer: {
                type: &quot;uniform&quot;
            }
        }
    ]
});
const bindGroup = device.createBindGroup({
    layout: bindGroupLayout,
    entries: [
        {
            binding: 0,
            resource: {
                buffer: projectionBuffer,
            }
        }, {
            binding: 1,
            resource: {
                buffer: angleBufferGPU,
            }
        }
    ]
});
</code></pre>
<p>Now, just multiply a rotation matrix before sending position to the projection matrix.</p>
<pre><code class="language-wgsl">const get_shader = async (device: GPUDevice): Promise&lt;GPUShaderModule&gt; =&gt; {
    return device.createShaderModule({
        label: &quot;sm&quot;,
        code: `
        @group(0) @binding(0) var&lt;uniform&gt; projection: mat3x2&lt;f32&gt;;
        @group(0) @binding(1) var&lt;uniform&gt; angle: f32;

        struct VertexOutput {
            @builtin(position) pos: vec4f,
            @location(0) @interpolate(flat) face: u32,
            @location(1) depth: f32,
        };

        @vertex
        fn vertexMain(@location(0) position: vec3f, @builtin(vertex_index) vertexIndex: u32) -&gt; VertexOutput {

            let rotation = mat3x3&lt;f32&gt;(
                vec3&lt;f32&gt;(cos(angle), 0.0, sin(angle)),
                vec3&lt;f32&gt;(0.0, 1.0, 0.0),
                vec3&lt;f32&gt;(-sin(angle), 0.0, cos(angle))
            );

            let rotated = rotation * position;

            let projected = projection * rotated;
            let final_position = vec4&lt;f32&gt;(projected, 0.0, 1.0);
            let depth = rotated.z * 0.5 + 0.5;

            var output = VertexOutput(final_position, vertexIndex / 6, depth);
            return output;
        }

        struct FragmentOutput {
            @location(0) color: vec4&lt;f32&gt;,
            @builtin(frag_depth) depth: f32,
        };

        @fragment
        fn fragmentMain(input: VertexOutput) -&gt; FragmentOutput {
            var output = FragmentOutput(vec4&lt;f32&gt;(1.0, 1.0, 1.0, 1.0), input.depth);
            if (input.face == 0u) {
                output.color = vec4&lt;f32&gt;(1.0, 0.0, 0.0, 1.0);
            } else if (input.face == 1u) {
                output.color = vec4&lt;f32&gt;(0.0, 1.0, 0.0, 1.0);
            } else if (input.face == 2u) {
                output.color = vec4&lt;f32&gt;(0.0, 0.0, 1.0, 1.0);
            } else if (input.face == 3u) {
                output.color = vec4&lt;f32&gt;(1.0, 1.0, 0.0, 1.0);
            } else if (input.face == 4u) {
                output.color = vec4&lt;f32&gt;(1.0, 0.0, 1.0, 1.0);
            } else {
                output.color = vec4&lt;f32&gt;(0.0, 1.0, 1.0, 1.0);
            }
            return output;
        }
        `,
    })
}
</code></pre>
<p>Now you can rotate the cube with the slider.</p>
<p>When doing rotation, it is better to adopt isometric view of the orthographic projection, since it is more intuitive.</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/jquery-3.6.0.min.js"></script>
        <script src="../js/bootstrap.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
